Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "D:\Workspace\DO AN TOT NGHIEP\Fake-News-Detection-master\Fake_News_Article\train.py", line 128, in <module>
    probas = bert_clf(token_ids, masks)
  File "C:\Users\Admin\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Workspace\DO AN TOT NGHIEP\Fake-News-Detection-master\Fake_News_Article\train.py", line 99, in forward
    _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)
  File "C:\Users\Admin\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: BertModel.forward() got an unexpected keyword argument 'output_all_encoded_layers'